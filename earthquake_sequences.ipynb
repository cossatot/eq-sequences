{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Earthquake Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Event Catalogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scripts import make_puget_sequence_gms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fault_geojson = 'data/puget_sound_ruptures.geojson'\n",
    "with open(fault_geojson, 'r') as f:\n",
    "    trace_dict = json.load(f)\n",
    "    traces = trace_dict['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites_file = \"data/nw_washington_sites.csv\"\n",
    "lons, lats = np.loadtxt(sites_file, delimiter=',', unpack=True)\n",
    "sites = SiteCollection([Site(location=Point(lon, lat), vs30=760.,\n",
    "                             vs30measured=True, z1pt0=40., z2pt5=1.)\n",
    "                        for lon, lat in zip(lons, lats)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mainshocks\n",
    "mainshock_ruptures = {trace['properties']['event']: trace_to_rupture(trace)\n",
    "                      for trace in tqdm(traces)}\n",
    "mainshock_ruptures_file = \"data/mainshock_ruptures.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aftershocks\n",
    "n_days = 1000 # days after event\n",
    "cutoff_mag = 4.5\n",
    "\n",
    "aftershock_ruptures = {k: make_aftershock_rupture_sequence(rup, n_days,\n",
    "                                                     min_return_mag=cutoff_mag)\n",
    "                       for k, rup in tqdm(mainshock_ruptures.items())}\n",
    "aftershock_ruptures_file = \"data/aftershock_ruptures.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ground Motion Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainshock_gms = {k: ground_motion_from_rupture(rup, sites=sites)\n",
    "                 for k, rup in tqdm(mainshock_ruptures.items())}\n",
    "mainshock_gms_file = \"data/mainshock_gms.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in tqdm(aftershock_ruptures.keys()):\n",
    "    calc_aftershock_gms(aftershock_ruptures[k], sites, n_jobs=-1, _joblib=False)\n",
    "aftershock_gms_file = \"data/aftershock_gms.csv\"\n",
    "eid = 0\n",
    "mid = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(mainshock_gms_file, 'w') as mgfile, \\\n",
    "     open(mainshock_ruptures_file, 'w') as mrfile, \\\n",
    "     open(aftershock_gms_file, 'w') as agfile, \\\n",
    "     open(aftershock_ruptures_file, 'w') as arfile:\n",
    "    frm = csv.writer(mrfile)\n",
    "    fgm = csv.writer(mgfile)\n",
    "    fra = csv.writer(arfile)\n",
    "    fga = csv.writer(agfile)\n",
    "    frm.writerow([\"eid\", \"event\", \"mag\", \"lon\", \"lat\", \"depth\"])\n",
    "    fgm.writerow([\"rlzi\", \"sid\", \"eid\", \"gmv_PGA\"])\n",
    "    fra.writerow([\"eid\", \"aid\", \"mainshock\", \"mag\", \"lon\", \"lat\", \"depth\"])\n",
    "    fga.writerow([\"rlzi\", \"sid\", \"eid\", \"gmv_PGA\"])\n",
    "    for k, rup in tqdm(mainshock_ruptures.items()):\n",
    "        aid = 0\n",
    "        frm.writerow([mid, k, rup.mag,\n",
    "                     rup.hypocenter.longitude, rup.hypocenter.latitude,\n",
    "                     rup.hypocenter.depth])\n",
    "        fra.writerow([eid, aid, k, rup.mag,\n",
    "                     rup.hypocenter.longitude, rup.hypocenter.latitude,\n",
    "                     rup.hypocenter.depth])\n",
    "        gmf = mainshock_gms[k]\n",
    "        for (sid, _), gmv in np.ndenumerate(gmf[PGA()]):\n",
    "            fgm.writerow([0, sid, mid, gmv])\n",
    "            fga.writerow([0, sid, eid, gmv])\n",
    "        eid += 1\n",
    "        mid += 1\n",
    "        aid += 1\n",
    "        for i in aftershock_ruptures[k].keys():\n",
    "            arup = aftershock_ruptures[k][i]\n",
    "            fra.writerow([eid, aid, k, arup[\"Mw\"],\n",
    "                          arup[\"lon\"], arup[\"lat\"], arup[\"depth\"]])\n",
    "            agmf = arup[\"ground_motion\"]\n",
    "            for (sid, _), gmv in np.ndenumerate(agmf[PGA()]):\n",
    "                fga.writerow([0, sid, eid, gmv])\n",
    "            aid += 1\n",
    "            eid += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building Exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openquake.commonlib import readinput\n",
    "from openquake.risklib import riskinput\n",
    "\n",
    "job_ini = \"models/calc_losses_nw_wa.ini\"\n",
    "\n",
    "oq = readinput.get_oqparam(job_ini)\n",
    "# read the exposure\n",
    "exposure = readinput.get_exposure(oq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Base Fragility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Damage Dependent Fragility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Building Recovery Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Damage to Loss Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Loss Estimates without Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Loss Estimates with Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
